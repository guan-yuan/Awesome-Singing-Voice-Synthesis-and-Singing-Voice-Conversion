# Awesome Singing Voice Conversion and Synthesis
A paper and project list about singing (singing voice synthesis and singing voice conversion), voice conversion, and related interesting works. 
  
Welcome to PR or contact me via email ([guanyuan@gapp.nthu.edu.tw](guanyuan@gapp.nthu.edu.tw)) for updating papers and works.

## Journals
IEEE/ACM TASLP, IEEE JSTSP, 


## Conferences
NeuraIPS, ICLR, ICML, IJAI, AAAI, ACL, NAACL, EMNLP, ISMIR, ICASSP, INTERSPEECH, ACM MM


## Workshops
ASRU,


## Singing Voice Conversion (Other Key Words: SVC, Singing Style Transfer)
- [Learn2Sing 2.0: Diffusion and Mutual Information-Based Target Speaker SVS by Learning from Singing Teacher](https://arxiv.org/abs/2203.16408) | **INTERSPEECH 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/WelkinYang/Learn2Sing2.0)
  + [Demo](https://welkinyang.github.io/Learn2Sing2.0/)

- [A Hierarchical Speaker Representation Framework for One-shot Singing Voice Conversion](https://arxiv.org/abs/2206.13762) | **INTERSPEECH 2022**
  + [Demo](https://lixucuhk.github.io/Unet-SVC-Demo/)

- [Controllable and Interpretable Singing Voice Decomposition via Assem-VC](https://arxiv.org/abs/2110.12676) | **NeurIPS 2021 Workshop** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/mindslab-ai/assem-vc)
  + [Demo](https://mindslab-ai.github.io/assem-vc/singer/)

- [DiffSVC: A Diffusion Probabilistic Model for Singing Voice Conversion](https://arxiv.org/abs/2105.13871) | **ASRU 2021**
  + [Demo](https://liusongxiang.github.io/diffsvc/)

- [FastSVC: Fast Cross-Domain Singing Voice Conversion with Feature-wise Linear Modulation](https://arxiv.org/abs/2011.05731) | **ICME 2021**
  + [Demo](https://nobody996.github.io/FastSVC/)

- [Unsupervised WaveNet-based Singing Voice Conversion Using Pitch Augmentation and Two-phase Approach](https://www.airitilibrary.com/Publication/alDetailedMesh1?DocID=U0001-1107202111044100) | 2021 [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/SongRongLee/mir-svc)
  + [Demo](https://songronglee.github.io/singing-voice-conversion/)

- [Towards High-fidelity Singing Voice Conversion with Acoustic Reference and Contrastive Predictive Coding](https://arxiv.org/abs/2110.04754) | 2021
  + [Demo](https://georgehappy1.github.io/svcdemo/)

- [Zero-shot Singing Voice Conversion](https://program.ismir2020.net/poster_1-08.html) | **ISMIR 2020**
  + [Demo](https://sites.google.com/izotope.com/ismir2020-audio-demo)

- [PitchNet: Unsupervised Singing Voice Conversion with Pitch Adversarial Network](https://arxiv.org/abs/1912.01852) | **ICASSP 2020**
  + [Demo](https://tencent-ailab.github.io/pitch-net/)

- [DurIAN-SC: Duration Informed Attention Network based Singing Voice Conversion System](https://arxiv.org/abs/2008.03009) | **INTERSPEECH 2020**
  + [Demo](https://tencent-ailab.github.io/learning_singing_from_speech/)

- [Unsupervised Cross-Domain Singing Voice Conversion](https://arxiv.org/abs/2008.02830) | **INTERSPEECH 2020**
  + [Demo](https://singing-conversion.github.io/)

- [VAW-GAN for Singing Voice Conversion with Non-parallel Training Data](https://arxiv.org/abs/2008.03992) | **APSIPA 2020** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/johndpope/Singing-Voice-Conversion-with-conditional-VAW-GAN)
  + [Demo](https://kunzhou9646.github.io/singvaw-gan/)

- [Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via Adversarial Training](https://arxiv.org/abs/2012.01837) | 2020
  + [Demo](https://hhguo.github.io/DemoEASVC/)
  + [Unofficial Code](https://github.com/hhguo/EA-SVC)

### Dateset
- [M4Singer: a Multi-Style, Multi-Singer and Musical Score Provided Mandarin Singing Corpus](https://openreview.net/forum?id=qiDmAaG6mP) | **NeurIPS 2022**
  + [Apply&Download](https://github.com/M4Singer/M4Singer)
  + [Demo](https://m4singer.github.io/)


## Voice Conversion (Other Key Words: VC, Voice Cloning, Voice Style Transfer)
- [End-to-End Zero-Shot Voice Style Transfer with Location-Variable Convolutions](https://arxiv.org/abs/2205.09784) | 2022
  + [Demo](https://lvc-vc.github.io/lvc-vc-demo/)

- [A Comparative Study of Self-supervised Speech Representation Based Voice Conversion](https://arxiv.org/abs/2207.04356) | **IEEE JSTSP 2022**

- [Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme](https://arxiv.org/abs/2109.13821) | **ICLR 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/huawei-noah/Speech-Backbones)
  + [Demo](https://diffvc-fast-ml-solver.github.io/)

- [YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice Conversion for everyone](https://arxiv.org/abs/2112.02418) | **ICML 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/edresson/yourtts)
  + [Demo](https://huggingface.co/spaces/ICML2022/YourTTS)
  + [Demo](https://edresson.github.io/YourTTS/)
  + [Blog](https://coqui.ai/blog/tts/yourtts-zero-shot-text-synthesis-low-resource-languages)

- [S3PRL-VC: Open-Source Voice Conversion Framework with Self-Supervised Speech Representations](https://ieeexplore.ieee.org/document/9746430) | **ICASSP 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/s3prl/s3prl/tree/master/s3prl/downstream/a2o-vc-vcc2020)

- [Assem-VC: Realistic Voice Conversion by Assembling Modern Speech Synthesis Techniques](https://arxiv.org/abs/2104.00931) | **ICASSP 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/mindslab-ai/assem-vc)
  + [Demo](https://mindslab-ai.github.io/assem-vc/)

- [Training Robust Zero-Shot Voice Conversion Models with Self-supervised Features](https://arxiv.org/abs/2112.04424) | **ICASSP 2022**
  + [Demo](https://trungd.github.io/ssl_vc/index.html)

- [Toward Degradation-Robust Voice Conversion](https://arxiv.org/abs/2110.07537) | **ICASSP 2022**

- [DGC-vector: A new speaker embedding for zero-shot voice conversion](https://arxiv.org/abs/2203.09722) | **ICASSP 2022**
  + [Demo](https://shaw0fr.github.io/DGC-vector-DEMO/)

- [Learning Noise-independent Speech Representation for High-quality Voice Conversion for Noisy Target Speakers](https://arxiv.org/abs/2207.00756) | **INTERSPEECH 2022**
  + [Demo](https://lmxue.github.io/FlowVC/)

- [Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion](https://arxiv.org/abs/2207.01832) | **INTERSPEECH 2022**
  + [Demo](https://leiyi420.github.io/glow-wavegan2/)

- [Any-to-Many Voice Conversion with Location-Relative Sequence-to-Sequence Modeling](https://arxiv.org/abs/2009.02725v3) | **IEEE/ACM TASLP 2021**
  + [Code](https://github.com/liusongxiang/ppg-vc)
  + [Demo](https://liusongxiang.github.io/BNE-Seq2SeqMoL-VC/)

- [Neural Analysis and Synthesis: Reconstructing Speech from Self-Supervised Representations](https://arxiv.org/abs/2110.14513) | **NeurIPS 2021**
  + [Demo](https://harsh-grenadilla-e40.notion.site/Demo-page-for-NANSY-37d4fd8ffb514765a2b234b04c8fc0f6)
  + [Unofficial Code](https://github.com/dhchoi99/NANSY)

- [Improving Zero-shot Voice Style Transfer via Disentangled Representation Learning](https://arxiv.org/abs/2103.09420) | **ICLR 2021**

- [Global Rhythm Style Transfer Without Text Transcriptions](https://arxiv.org/abs/2106.08519) | **ICML 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/auspicious3000/AutoPST)

- [AGAIN-VC: A One-shot Voice Conversion using Activation Guidance and Adaptive Instance Normalization](https://arxiv.org/abs/2011.00316) | **ICASSP 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/KimythAnly/AGAIN-VC)
  + [Demo](https://kimythanly.github.io/AGAIN-VC-demo/index)

- [StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for Natural-Sounding Voice Conversion](https://arxiv.org/abs/2107.10394) | **INTERSPEECH 2021 Best Paper Award** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/yl4579/StarGANv2-VC)
  + [Demo](https://starganv2-vc.github.io/)

- [S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations](https://arxiv.org/abs/2104.02901) | **INTERSPEECH 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/howard1337/S2VC)
  + [Demo](https://howard1337.github.io/S2VC/)

- [Many-to-Many Voice Conversion based Feature Disentanglement using Variational Autoencoder](https://arxiv.org/abs/2107.06642) | **INTERSPEECH 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/v-manhlt3/Disentangle-VAE-for-VC)
  + [Demo](https://v-manhlt3.github.io/disentangled-VAE/)

- [On Prosody Modeling for ASR+TTS based Voice Conversion](https://arxiv.org/abs/2107.09477) | **ASRU 2021**
  + [Demo](https://unilight.github.io/Publication-Demos/publications/prosody-asr-tts-vc/index.html)

- [MediumVC: Any-to-any voice conversion using synthetic specific-speaker speeches as intermedium features](https://arxiv.org/abs/2110.02500) | 2021 [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/BrightGu/MediumVC)
  + [Demo](https://brightgu.github.io/MediumVC/)

- [An Overview of Voice Conversion and its Challenges: From Statistical Modeling to Deep Learning](https://arxiv.org/abs/2008.03648) | **IEEE/ACM TASLP 2020**

- [Unsupervised Speech Decomposition via Triple Information Bottleneck](https://arxiv.org/abs/2004.11284) | **ICML 2020** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/auspicious3000/SpeechSplit)

- [AUTOVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss](https://arxiv.org/abs/1905.05879) | **ICML 2019** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/auspicious3000/autovc)

- [One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization](https://arxiv.org/abs/1904.05742) | **INTERSPEECH 2019** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/cyhuang-tw/AdaIN-VC)


## Emotional Voice Conversion
- [Disentanglement of Emotional Style and Speaker Identity for Expressive Voice Conversion](https://arxiv.org/abs/2110.10326) | **INTERSPEECH 2022**
  + [Demo](https://zy-du.github.io/IS22/)

- [Cross-speaker Emotion Transfer Based On Prosody Compensation for End-to-End Speech Synthesis](https://arxiv.org/abs/2207.01198) | **INTERSPEECH 2022**
  + [Demo](https://silyfox.github.io/cspc/)

- [Emotion Intensity and its Control for Emotional Voice Conversion](https://arxiv.org/abs/2201.03967) | **IEEE Transactions on Affective Computing** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/KunZhou9646/Emovox)
  + [Demo](https://kunzhou9646.github.io/Emovox_demo/)

- [Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-stage Sequence-to-Sequence Training](https://arxiv.org/abs/2103.16809) | **INTERSPEECH 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/KunZhou9646/seq2seq-EVC)
  + [Demo](https://kunzhou9646.github.io/IS21/)

- [Converting Anyone's Emotion: Towards Speaker-Independent Emotional Voice Conversion](https://arxiv.org/abs/2005.07025) | **INTERSPEECH 2020** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/KunZhou9646/Speaker-independent-emotional-voice-conversion-based-on-conditional-VAW-GAN-and-CWT)
  + [Demo](https://kunzhou9646.github.io/speaker-independent-emotional-vc/)

- [Transforming Spectrum and Prosody for Emotional Voice Conversion with Non-Parallel Training Data](https://arxiv.org/abs/2002.00198) | **Odyssey 2020** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/KunZhou9646/emotional-voice-conversion-with-CycleGAN-and-CWT-for-Spectrum-and-F0)
  + [Demo](https://kunzhou9646.github.io/Odyssey2020_emotional_VC//)


## Singing Voice Synthesis (Other Key Words: SVS)
- [WeSinger 2: Fully Parallel Singing Voice Synthesis via Multi-Singer Conditional Adversarial Training](https://arxiv.org/abs/2207.01886) | 2022
  + [Demo](https://zzw922cn.github.io/wesinger2/)

- [DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism](https://arxiv.org/abs/2105.02446) | **AAAI 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/MoonInTheRiver/DiffSinger)
  + [Demo](https://diffsinger.github.io/)

- [Learning the Beauty in Songs: Neural Singing Voice Beautifier](https://arxiv.org/abs/2202.13277) | **ACL 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/MoonInTheRiver/NeuralSVB)
  + [Demo](https://neuralsvb.github.io/)

- [Muskits: an End-to-End Music Processing Toolkit for Singing Voice Synthesis](https://arxiv.org/abs/2205.04029) | **INTERSPEECH 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/SJTMusicTeam/Muskits)

- [SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy](https://arxiv.org/abs/2203.17001) | **INTERSPEECH 2022** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/SJTMusicTeam/Muskits)

- [WeSinger: Data-augmented Singing Voice Synthesis with Auxiliary Losses](https://arxiv.org/abs/2203.10750?s=03) | **INTERSPEECH 2022**
  + [Demo](https://zzw922cn.github.io/wesinger/)

- [Sinsy: A Deep Neural Network-Based Singing Voice Synthesis System](https://arxiv.org/abs/2108.02776) | **IEEE/ACM TASLP 2021** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/r9y9/nnsvs)

### Dateset
- [PopCS](https://arxiv.org/abs/2105.02446) | **AAAI 2022**
  + [Apply&Download](https://github.com/MoonInTheRiver/DiffSinger/blob/master/resources/apply_form.md)

- [Opencpop: A High-Quality Open Source Chinese Popular Song Corpus for Singing Voice Synthesis](https://arxiv.org/abs/2201.07429) | **INTERSPEECH 2022**
  + [Apply&Download](https://wenet.org.cn/opencpop/)


## Vocoder
- [Towards achieving robust universal neural vocoding](https://arxiv.org/abs/1811.06292) | **INTERSPEECH 2019** [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/bshall/UniversalVocoding)
  + [Unofficial Code](https://github.com/yistLin/universal-vocoder)
  + [Demo](https://bshall.github.io/UniversalVocoding/)


## Self-supervised/Unsupervised ASR
- [Representation Learning with Contrastive Predictive Coding](https://arxiv.org/abs/1807.03748) | 2019 [‚úîÔ∏è**With Code**]
  + [Code](https://github.com/facebookresearch/CPC_audio)


## TTS
- [RetrieverTTS: Modeling Decomposed Factors for Text-Based Speech Insertion](https://arxiv.org/abs/2206.13865) | **INTERSPEECH 2022**
  + [Demo](https://ydcustc.github.io/retrieverTTS-demo/)


## ASR Toolkits
- [S3PRL Toolkit](https://github.com/s3prl/s3prl)
- [WeNet](https://github.com/wenet-e2e/wenet)


## TTS Toolkits
- [Coqui.ai TTS](https://github.com/coqui-ai/TTS)


## Competitions
- [Voice Conversion Challenge 2020](http://www.vc-challenge.org/)
  + [Apply&Download](https://github.com/nii-yamagishilab/VCC2020-database)


## References
- [Awesome Speech Recognition Speech Synthesis Papers](https://github.com/zzw922cn/awesome-speech-recognition-speech-synthesis-papers)
- [Awesome Voice Conversion Papers Projects](https://github.com/JeffC0628/awesome-voice-conversion)
- [TTS Papers](http://yqli.tech/page/tts_paper.html)
- [üê∏ TTS papers](https://github.com/coqui-ai/TTS-papers)
- [Speech Synthesis Paper](https://github.com/wenet-e2e/speech-synthesis-paper)
- [Papers With Code: Voice Conversion](https://paperswithcode.com/task/voice-conversion)
- [Papers With Code: Singing Voice Conversion](https://paperswithcode.com/search?q_meta=&q_type=&q=singing+voice+conversion)
- [Papers With Code: Singing Voice Synthesis](https://paperswithcode.com/search?q_meta=&q_type=&q=singing+voice+synthesis)
- [Awesome Open Source: Voice Conversion](https://awesomeopensource.com/projects/voice-conversion)
- [ICASSP 2021 Paper List-VC](https://github.com/xinshengwang/ICASSP2021_paper_list-VC)



